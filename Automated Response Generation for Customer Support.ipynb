{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832e6479-db20-418b-b9f4-5b9485fd507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets --quiet\n",
    "# !pip install sentencepiece --quiet\n",
    "# !pip install accelerate -U --quiet\n",
    "# !pip install scikit-learn --quiet\n",
    "# !pip install sacrebleu --quiet\n",
    "# !pip install tensorboard --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc7ef82-b547-4eba-af1a-3b74665b36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaabi\\anaconda3\\envs\\csr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sacrebleu\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from hyperparameters import *\n",
    "import numpy as np\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678e8a59-fc30-4973-8c56-3daa4584e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset(dataset, val_size = .1):\n",
    "    t,v = dataset['train'].train_test_split(test_size = val_size).values()\n",
    "    return t, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce43b3be-85bb-4d9e-8d76-03546f33e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET)\n",
    "train_dataset, val_dataset = get_validation_dataset(dataset)\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7b2b79-351f-43b8-93e7-b2a5a7d1505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    inputs = [pretext + d.lower() for d in data['query']]\n",
    "    targets = [d.lower() for d in data['response']]\n",
    "    model_inputs = tokenizer(inputs, max_length= max_source_length, truncation=True, padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length= max_target_length, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fee2fe3-03a0-4a7b-bff6-33fbe04def17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaabi\\anaconda3\\envs\\csr\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map:   0%|                                                                               | 0/66 [00:00<?, ? examples/s]C:\\Users\\jaabi\\anaconda3\\envs\\csr\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 1367.51 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 283.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711c1fbe-f4fa-4276-b614-18c8a241474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens = True)\n",
    "    return {'bleu' : sacrebleu.corpus_bleu(predictions, labels).score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92872475-8f50-4cb3-9578-429969637404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaabi\\anaconda3\\envs\\csr\\Lib\\site-packages\\accelerate\\accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args         = Seq2SeqTrainingArguments(**TRAINING_ARGS)\n",
    "data_collator         = DataCollatorForSeq2Seq(tokenizer, model = model)\n",
    "trainer               = Seq2SeqTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = tokenized_train_dataset,\n",
    "    eval_dataset    = tokenized_val_dataset,\n",
    "    compute_metrics = compute_bleu,\n",
    "    data_collator   = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10203bd-9d89-4a4b-b37d-1d7297f95b70",
   "metadata": {},
   "source": [
    "#### Trained the model with the pretext : `Assure the customer and provide specific help`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26abf0f-a910-4668-8746-2eca56f8ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 02:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.554859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.336999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223310</td>\n",
       "      <td>0.176954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213184</td>\n",
       "      <td>0.215842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204392</td>\n",
       "      <td>0.228775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199596</td>\n",
       "      <td>0.215842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.185310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196068</td>\n",
       "      <td>0.226309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193811</td>\n",
       "      <td>0.243882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./models\\checkpoint-17 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=170, training_loss=0.735866995418773, metrics={'train_runtime': 121.9824, 'train_samples_per_second': 5.411, 'train_steps_per_second': 1.394, 'total_flos': 401912207769600.0, 'train_loss': 0.735866995418773, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09840542-c5c6-4e88-adcc-8ecf52254020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query    : Where can I find your sizing chart?\n",
      "Response : We'd be happy to help. Can you please provide the product name or SKU so we can direct you to the appropriate sizing chart?\n",
      "Predicted: we'd be happy to help. can you please provide your order number and the product name or sku you're interested in?\n",
      "\n",
      "Query    : I need to return an item.\n",
      "Response : Certainly. Please provide your order number and reason for return, and we will provide you with instructions on how to proceed.\n",
      "Predicted: we apologize for the inconvenience. can you please provide the product name or sku so we can assist you further?\n",
      "\n",
      "Query    : How long does shipping take?\n",
      "Response : We'd be happy to provide an estimate. Can you please provide your shipping destination and the product name or SKU?\n",
      "Predicted: we'd be happy to help. can you please provide your shipping destination and the product name or sku?\n",
      "\n",
      "Query    : Can I pre-order an item?\n",
      "Response : Certainly. Can you please provide the product name or SKU and your email address so we can notify you when pre-orders are available?\n",
      "Predicted: yes, you can pre-order items online. can you please provide the product name or sku so we can check availability?\n",
      "\n",
      "Query    : I received a damaged product.\n",
      "Response : We apologize for the inconvenience. Can you please provide a photo of the damaged product so we can assist you further?\n",
      "Predicted: we apologize for the inconvenience. can you please provide the product name or sku so we can assist you further?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(query, model):\n",
    "    query = pretext + query.lower()\n",
    "    input_ids = tokenizer.encode(query, return_tensors='pt', max_length=max_source_length, truncation=True)\n",
    "    if torch.cuda.is_available(): input_ids = input_ids.to('cuda')\n",
    "    output_ids = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "inds = np.random.choice(np.arange(len(dataset['train'])), 5)\n",
    "queries = dataset['train']['query']\n",
    "responses = dataset['train']['response']\n",
    "\n",
    "for i in inds:\n",
    "    q = queries[i]\n",
    "    response = generate_response(q, model)\n",
    "    print('Query    : ' + q)\n",
    "    print('Response : ' + responses[i])\n",
    "    print('Predicted: ' + response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268017e-f0e2-42f2-912d-98e543e8d2c0",
   "metadata": {},
   "source": [
    "#### Trained the model with the pretext : `Generate meaningful customer support response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee21aff3-50d7-4a4e-ba48-77c150330ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 02:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558074</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310823</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232266</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214262</td>\n",
       "      <td>0.229969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198647</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193539</td>\n",
       "      <td>0.196662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197325</td>\n",
       "      <td>0.191334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200803</td>\n",
       "      <td>0.176072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202593</td>\n",
       "      <td>0.184343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202748</td>\n",
       "      <td>0.184343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./models\\checkpoint-17 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=170, training_loss=0.7351306242101333, metrics={'train_runtime': 123.9108, 'train_samples_per_second': 5.326, 'train_steps_per_second': 1.372, 'total_flos': 401912207769600.0, 'train_loss': 0.7351306242101333, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87db5f24-c571-4135-866b-e2c94dfb9b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query    : Where can I find your sizing chart?\n",
      "Response : We'd be happy to help. Can you please provide the product name or SKU so we can direct you to the appropriate sizing chart?\n",
      "Predicted: we'd be happy to help. can you please provide the product name or sku and the product name or sku you're interested in?\n",
      "\n",
      "Query    : I need to return an item.\n",
      "Response : Certainly. Please provide your order number and reason for return, and we will provide you with instructions on how to proceed.\n",
      "Predicted: we apologize for the inconvenience. can you please provide the product name or sku so we can assist you?\n",
      "\n",
      "Query    : How long does shipping take?\n",
      "Response : We'd be happy to provide an estimate. Can you please provide your shipping destination and the product name or SKU?\n",
      "Predicted: we'd be happy to help. can you please provide your shipping address so we can send you a quote?\n",
      "\n",
      "Query    : Can I pre-order an item?\n",
      "Response : Certainly. Can you please provide the product name or SKU and your email address so we can notify you when pre-orders are available?\n",
      "Predicted: can you please provide the product name or sku so we can check availability?\n",
      "\n",
      "Query    : I received a damaged product.\n",
      "Response : We apologize for the inconvenience. Can you please provide a photo of the damaged product so we can assist you further?\n",
      "Predicted: we apologize for the inconvenience. can you please provide the product name or sku and the product name or sku you're interested in?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(query, model):\n",
    "    query = pretext + query.lower()\n",
    "    input_ids = tokenizer.encode(query, return_tensors='pt', max_length=max_source_length, truncation=True)\n",
    "    if torch.cuda.is_available(): input_ids = input_ids.to('cuda')\n",
    "    output_ids = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "inds = np.random.choice(np.arange(len(dataset['train'])), 5)\n",
    "queries = dataset['train']['query']\n",
    "responses = dataset['train']['response']\n",
    "\n",
    "for i in inds:\n",
    "    q = queries[i]\n",
    "    response = generate_response(q, model)\n",
    "    print('Query    : ' + q)\n",
    "    print('Response : ' + responses[i])\n",
    "    print('Predicted: ' + response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4372788f-1504-4342-b25f-494260c36268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5-customer-support\\\\tokenizer_config.json',\n",
       " 't5-customer-support\\\\special_tokens_map.json',\n",
       " 't5-customer-support\\\\spiece.model',\n",
       " 't5-customer-support\\\\added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(SAVE_AS)\n",
    "tokenizer.save_pretrained(SAVE_AS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8aeb2f-a926-4aa6-bb65-df679fe13dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{SAVE_DIR}'/runs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6abc0-df8e-4823-b864-57065b091e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
